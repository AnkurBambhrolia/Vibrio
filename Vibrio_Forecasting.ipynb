{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfVZw67DxwxLuJYiZCKbq1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkurBambhrolia/Vibrio/blob/main/Vibrio_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Forecasting"
      ],
      "metadata": {
        "id": "1bqfW8TvqPXV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsrWv97wphMv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Redo and use average file (Only redo Isolates)\n",
        "# Import CSV from Github\n",
        "df_source = 'https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg.csv'  # Use 'raw' URL\n",
        "df_source = pd.read_csv(df_source)\n",
        "df_source\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#List of states for each region\n",
        "gulf_states = ['Alabama', 'Florida', 'Georgia', 'Louisiana', 'Mississippi', 'Texas']\n",
        "east_states = ['Georgia', 'South Carolina', 'North Carolina', 'Virginia', 'Maryland', 'Delaware', 'New Jersey', 'New York', 'Connecticut', 'Rhode Island', 'Massachusetts', 'New Hampshire', 'Maine']\n",
        "\n",
        "#Add a region column\n",
        "df_source['region'] = df_source['state_name'].apply(lambda x: 'Gulf' if x in gulf_states else 'East' if x in east_states else 'Other')\n",
        "\n",
        "#Verify the new column\n",
        "df_source.head(12)\n",
        "\n",
        "# Save file\n",
        "# df_source.to_csv('vv_sst_sss_sources_region_avg.csv', index=False)\n",
        "\n",
        "# Download file\n",
        "# from google.colab import files\n",
        "# files.download('vv_sst_sss_sources_region_avg.csv')"
      ],
      "metadata": {
        "id": "Kz4qtC9FqXs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redo and use average file (Only redo Isolates)\n",
        "# Import CSV from Github\n",
        "df_source = 'https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg.csv'  # Use 'raw' URL\n",
        "df_source = pd.read_csv(df_source)\n",
        "df_source.columns\n",
        "\n",
        "# Convert columns to appropriate data types\n",
        "df_source['Year'] = pd.to_numeric(df_source['Year'], errors='coerce')\n",
        "df_source['Month'] = pd.to_numeric(df_source['Month'], errors='coerce')\n",
        "df_source['sst'] = pd.to_numeric(df_source['sst'], errors='coerce')\n",
        "df_source['sss'] = pd.to_numeric(df_source['sss'], errors='coerce')\n",
        "df_source['Number_of_isolates'] = pd.to_numeric(df_source['Number_of_isolates'], errors='coerce')\n",
        "\n",
        "# Create a datetime column\n",
        "df_source['Date'] = pd.to_datetime(df_source[['Year', 'Month']].assign(DAY=1), errors='coerce')\n",
        "\n",
        "# Group by Date and compute averages/sums\n",
        "time_series = df_source.groupby('Date').agg({\n",
        "    'sst': 'mean', #average of coordinates\n",
        "    'sss': 'mean', # average\n",
        "    'Number_of_isolates': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "time_series.head()"
      ],
      "metadata": {
        "id": "A3zBuo1eqbjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create three separate line charts for SST, SSS, and Number of Isolates\n",
        "\n",
        "# Plot 1: SST over time\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(time_series['Date'], time_series['sst'], color='blue')\n",
        "plt.title('Average Sea Surface Temperature (SST) Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('SST (Â°C)')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: SSS over time\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(time_series['Date'], time_series['sss'], color='green')\n",
        "plt.title('Average Sea Surface Salinity (SSS) Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('SSS (psu)')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot 3: Number of Isolates over time\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(time_series['Date'], time_series['Number_of_isolates'], color='red')\n",
        "plt.title('Total Vibrio vulnificus Isolates Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Isolates')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J_GTE_Nxqelo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine Stationary or Non-Stationary"
      ],
      "metadata": {
        "id": "TJMEfn_Lqjqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Determine Statonary of of each variable (SSS, SST, Vibrio Count)\n",
        "\n",
        "\n",
        "# Use the Augmented Dickey-Fuller (ADF) test\n",
        "# It checks if your series has a unit root, which would imply non-stationarity.\n",
        "\n",
        "\n",
        "result_cases = adfuller(time_series['Number_of_isolates'].dropna())\n",
        "\n",
        "#print('ADF Statistic:', result[0])\n",
        "#print('p-value:', result[1])\n",
        "#print('Critical Values:')\n",
        "#for key, value in result[4].items():\n",
        "    #print(f'   {key}: {value}')\n",
        "\n",
        "\n",
        "\n",
        "result_sss = adfuller(time_series['sss'].dropna())\n",
        "\n",
        "#print('\\nADF Statistic:', result_sss[0])\n",
        "#print('p-value:', result_sss[1])\n",
        "#print('Critical Values:')\n",
        "#for key, value in result_sss[4].items():\n",
        "    #print(f'   {key}: {value}')\n",
        "\n",
        "\n",
        "results_sst = adfuller(time_series['sst'].dropna())\n",
        "\n",
        "#print('\\nADF Statistic:', results_sst[0])\n",
        "#print('p-value:', results_sst[1])\n",
        "#print('Critical Values:')\n",
        "#for key, value in results_sst[4].items():\n",
        "  #print(f'   {key}: {value}')\n",
        "\n",
        "pval_df = pd.DataFrame([\n",
        "                       ['Number_of_isolates', result_cases[0], result_cases[1], '0.05', \"Non-Stationary\"],\n",
        "                       ['sss', result_sss[0], result_sss[1], '0.05', \"Stationary\"],\n",
        "                       ['sst', results_sst[0], results_sst[1], '0.05', \"Stationary\"]],\n",
        "                       columns=['Variable', 'ADF Statistic', 'p-value', 'Critical Values', \"Interpertation\"])\n",
        "pval_df\n",
        "\n",
        "#from google.colab import files\n",
        "#results_df.to_csv(\"adf.csv\", index=False)\n",
        "#files.download(\"adf.csv\")\n"
      ],
      "metadata": {
        "id": "t7SGD8WYqg7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load and preprocess data\n",
        "url = 'https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg.csv'\n",
        "df = pd.read_csv(url)\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month']].assign(day=1))\n",
        "monthly_df = df.groupby('date')['Number_of_isolates'].sum().reset_index()\n",
        "vibrio_df = monthly_df.rename(columns={'date': 'ds', 'Number_of_isolates': 'y'})\n",
        "vibrio_df = vibrio_df[vibrio_df['y'] > 0].copy()\n",
        "vibrio_df.head()\n",
        "# 2. Set datetime index and enforce monthly frequency\n",
        "vibrio_df = vibrio_df.set_index('ds').asfreq('MS')\n",
        "vibrio_df['y'] = vibrio_df['y'].fillna(0)\n",
        "\n",
        "# 3. Feature engineering\n",
        "vibrio_df['year'] = vibrio_df.index.year\n",
        "vibrio_df['month'] = vibrio_df.index.month\n",
        "\n",
        "# 4. Train-test split (train on all data, forecast future)\n",
        "X = vibrio_df[['year', 'month']]\n",
        "y = vibrio_df['y']\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# 5. Forecast next 60 months\n",
        "last_date = vibrio_df.index.max()\n",
        "future_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), periods=60, freq='MS')\n",
        "future_df = pd.DataFrame({\n",
        "    'ds': future_dates,\n",
        "    'year': future_dates.year,\n",
        "    'month': future_dates.month\n",
        "})\n",
        "\n",
        "# 6. Make predictions\n",
        "forecast = rf.predict(future_df[['year', 'month']])\n",
        "forecast_df = pd.DataFrame({\n",
        "    'ds': future_df['ds'],\n",
        "    'forecast': np.clip(forecast, 0, None)  # No negative values\n",
        "})\n",
        "\n",
        "# Optional: Add dummy lower/upper CI bounds (not directly available from RF)\n",
        "# forecast_df['lower'] = forecast_df['forecast'] * 0.8\n",
        "# forecast_df['upper'] = forecast_df['forecast'] * 1.2\n",
        "\n",
        "# Preview\n",
        "print(forecast_df.head())\n",
        "\n",
        "# Combine historical and forecasted data\n",
        "vibrio_hist = vibrio_df[['y']].reset_index().rename(columns={'y': 'value'})\n",
        "vibrio_hist['type'] = 'historical'\n",
        "forecast_df = forecast_df.rename(columns={'forecast': 'value'})\n",
        "forecast_df['type'] = 'forecast'\n",
        "\n",
        "\n",
        "# 8. Plot results\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(vibrio_df.index, vibrio_df['y'], label='Historical', color='blue', lw = 2)\n",
        "plt.plot(forecast_df['ds'], forecast_df['value'], label='Forecast (Random Forest Regression)', color='orange', lw = 2)\n",
        "# Vertical line at transition\n",
        "plt.axvline(x=forecast_df['ds'].min(), color='magenta', linestyle='--', label='Forecast Start', alpha = 0.8)\n",
        "# plt.fill_between(forecast_df['ds'], forecast_df['lower'], forecast_df['upper'], color='orange', alpha=0.3)\n",
        "plt.title('60 Month Forecast of Vibrio vulnificus Cases (Random Forest Regression)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Confirmed')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "# Show Plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 9. Combine historical and forecasted data\n",
        "vibrio_hist = vibrio_df[['y']].reset_index().rename(columns={'y': 'value'})\n",
        "vibrio_hist['type'] = 'historical'\n",
        "forecast_df = forecast_df.rename(columns={'forecast': 'value'})\n",
        "forecast_df['type'] = 'forecast'\n",
        "\n",
        "# 10. Combine and export\n",
        "combined_df = pd.concat([vibrio_hist, forecast_df], axis=0, ignore_index=True)\n",
        "combined_df = combined_df.sort_values(by='ds')\n",
        "combined_df.to_csv('vibrio_isolates_historical_forecast.csv', index=False)\n",
        "\n",
        "from google.colab import files\n",
        "#files.download('vibrio_isolates_historical_forecast.csv')\n"
      ],
      "metadata": {
        "id": "lPktLXkHqpW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "# Import data\n",
        "github = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df = pd.read_csv(github)\n",
        "# Create 'date' column from 'Year' and 'Month'\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month']].assign(day=1))\n",
        "\n",
        "# Aggregate Vibrio cases by month and region\n",
        "cases_by_region = (\n",
        "    df.groupby(['date', 'region'])['Number_of_isolates']\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Pivot for time series plotting\n",
        "pivot_cases = cases_by_region.pivot(index='date', columns='region', values='Number_of_isolates')\n",
        "\n",
        "# Plot time series for each region\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.lineplot(data=pivot_cases)\n",
        "plt.title(\"Time Series of Vibrio vulnificus Cases by Region\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of Isolates\")\n",
        "plt.legend(title=\"Region\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Run ADF test for each region\n",
        "adf_results = []\n",
        "for region in pivot_cases.columns:\n",
        "    series = pivot_cases[region].dropna()\n",
        "    result = adfuller(series)\n",
        "    adf_results.append({\n",
        "        'Region': region,\n",
        "        'ADF Statistic': result[0],\n",
        "        'p-value': result[1],\n",
        "        'Critical Value (5%)': result[4]['5%'],\n",
        "        'Stationary at 5%': result[1] < 0.05\n",
        "    })\n",
        "\n",
        "# Display results as a DataFrame\n",
        "adf_df = pd.DataFrame(adf_results)\n",
        "display(adf_df)"
      ],
      "metadata": {
        "id": "JKxk3EySrG9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning Data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "github = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df = pd.read_csv(github)\n",
        "\n",
        "# Combine Year and Month into a datetime column\n",
        "df['Date'] = pd.to_datetime(df[['Year', 'Month']].assign(DAY=1))\n",
        "\n",
        "# Filter for relevant columns and regions\n",
        "df = df[['Date', 'region', 'Number_of_isolates']]\n",
        "df = df[df['region'].isin(['East', 'Gulf'])]\n",
        "\n",
        "# Aggregate the data: sum of isolates per region per month\n",
        "agg_df = df.groupby(['Date', 'region'])['Number_of_isolates'].sum().reset_index()\n",
        "\n",
        "# Pivot to wide format for comparison\n",
        "pivot_df = agg_df.pivot(index='Date', columns='region', values='Number_of_isolates')\n",
        "\n",
        "from IPython.display import display; display(pivot_df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "3V3gIpLkrJS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeling\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Load and preprocess data\n",
        "github = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df = pd.read_csv(github)\n",
        "df['Date'] = pd.to_datetime(df[['Year', 'Month']].assign(day=1))\n",
        "df = df[['Date', 'region', 'Number_of_isolates']]\n",
        "df = df[df['region'].isin(['East', 'Gulf'])]\n",
        "\n",
        "# Aggregate\n",
        "agg_df = df.groupby(['Date', 'region'])['Number_of_isolates'].sum().reset_index()\n",
        "pivot_df = agg_df.pivot(index='Date', columns='region', values='Number_of_isolates')\n",
        "pivot_df_filled = pivot_df.asfreq('MS').fillna(0)\n",
        "\n",
        "# Define model evaluation and visualization function\n",
        "def run_models_updated(region_name, series):\n",
        "    results = []\n",
        "    series = series.asfreq('MS')\n",
        "    train = series[:-6]\n",
        "    test = series[-6:]\n",
        "\n",
        "    # SARIMA\n",
        "    sarima_model = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,12)).fit(disp=False)\n",
        "    sarima_forecast = sarima_model.get_forecast(steps=6)\n",
        "    sarima_mean = sarima_forecast.predicted_mean\n",
        "    sarima_ci = sarima_forecast.conf_int()\n",
        "\n",
        "    mae_s = mean_absolute_error(test, sarima_mean)\n",
        "    rmse_s = sqrt(mean_squared_error(test, sarima_mean))\n",
        "    results.append(['SARIMA', region_name, mae_s, rmse_s])\n",
        "\n",
        "    # Smoothed Rolling Regression\n",
        "    smoothed = train.rolling(window=3, min_periods=1).mean()\n",
        "    x_train = np.arange(len(smoothed)).reshape(-1, 1)\n",
        "    y_train = smoothed.values\n",
        "    x_test = np.arange(len(smoothed), len(smoothed) + 6).reshape(-1, 1)\n",
        "    lin_model = LinearRegression().fit(x_train, y_train)\n",
        "    smooth_forecast = lin_model.predict(x_test)\n",
        "    mae_smooth = mean_absolute_error(test, smooth_forecast)\n",
        "    rmse_smooth = sqrt(mean_squared_error(test, smooth_forecast))\n",
        "    results.append(['Smoothed Rolling Regression', region_name, mae_smooth, rmse_smooth])\n",
        "\n",
        "    # Rolling Mean Forecast\n",
        "    rolling_forecast = [train.rolling(window=3).mean().iloc[-1]] * 6\n",
        "    mae_roll = mean_absolute_error(test, rolling_forecast)\n",
        "    rmse_roll = sqrt(mean_squared_error(test, rolling_forecast))\n",
        "    results.append(['Rolling Mean', region_name, mae_roll, rmse_roll])\n",
        "\n",
        "    # Linear Regression\n",
        "    x_train_plain = np.arange(len(train)).reshape(-1, 1)\n",
        "    y_train_plain = train.values\n",
        "    x_test_plain = np.arange(len(train), len(train) + 6).reshape(-1, 1)\n",
        "    lin_model_plain = LinearRegression().fit(x_train_plain, y_train_plain)\n",
        "    lin_forecast = lin_model_plain.predict(x_test_plain)\n",
        "    mae_lin = mean_absolute_error(test, lin_forecast)\n",
        "    rmse_lin = sqrt(mean_squared_error(test, lin_forecast))\n",
        "    results.append(['Linear Regression', region_name, mae_lin, rmse_lin])\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(series.index, series, label='Actual', color='black')\n",
        "    plt.plot(test.index, sarima_mean, label='SARIMA', color='blue')\n",
        "\n",
        "    # Use correct CI column names dynamically\n",
        "    ci_lower = sarima_ci[f'lower {region_name}'].astype(float)\n",
        "    ci_upper = sarima_ci[f'upper {region_name}'].astype(float)\n",
        "    plt.fill_between(test.index, ci_lower.values, ci_upper.values, color='blue', alpha=0.2)\n",
        "\n",
        "    plt.plot(test.index, smooth_forecast, label='Smoothed Rolling Regression', color='green')\n",
        "    plt.plot(test.index, rolling_forecast, label='Rolling Mean', color='orange')\n",
        "    plt.plot(test.index, lin_forecast, label='Linear Regression', color='purple')\n",
        "    plt.title(f\"{region_name} Region - Forecast Comparison\")\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Number of Isolates')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run models\n",
        "east_results_updated = run_models_updated('East', pivot_df_filled['East'])\n",
        "gulf_results_updated = run_models_updated('Gulf', pivot_df_filled['Gulf'])\n",
        "\n",
        "# Combine and view results\n",
        "final_results_updated = pd.DataFrame(\n",
        "    east_results_updated + gulf_results_updated,\n",
        "    columns=['Model', 'Region', 'MAE', 'RMSE']\n",
        ")\n",
        "\n",
        "# Display\n",
        "print(\"Model Comparison by Region\")\n",
        "display(final_results_updated)\n",
        "\n",
        "#  Save results to CSV\n",
        "final_results_updated.to_csv(\"vibrio_model_comparison_by_region.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "#files.download(\"vibrio_model_comparison_by_region.csv\")"
      ],
      "metadata": {
        "id": "86Bz4RaBrR3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecast 60 months into the future for both regions using SARIMA\n",
        "\n",
        "# Function to forecast future values using SARIMA\n",
        "def forecast_future_sarima(series, region_name, steps=60):\n",
        "    series = series.asfreq('MS')\n",
        "    model = SARIMAX(series, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12),\n",
        "                    enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)\n",
        "    forecast_result = model.get_forecast(steps=steps)\n",
        "    forecast_mean = forecast_result.predicted_mean.clip(lower=0)\n",
        "    forecast_ci = forecast_result.conf_int().clip(lower=0)\n",
        "\n",
        "    # Create future date range\n",
        "    last_date = series.index.max()\n",
        "    future_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), periods=steps, freq='MS')\n",
        "\n",
        "    forecast_df = pd.DataFrame({\n",
        "        'Date': future_dates,\n",
        "        'Region': region_name,\n",
        "        'Forecast': forecast_mean.values,\n",
        "        'Lower_CI': forecast_ci.iloc[:, 0].values,\n",
        "        'Upper_CI': forecast_ci.iloc[:, 1].values\n",
        "    })\n",
        "\n",
        "    return forecast_df\n",
        "\n",
        "# Generate forecasts\n",
        "east_forecast = forecast_future_sarima(pivot_df_filled['East'], 'East')\n",
        "gulf_forecast = forecast_future_sarima(pivot_df_filled['Gulf'], 'Gulf')\n",
        "\n",
        "# Combine forecasts\n",
        "combined_forecast = pd.concat([east_forecast, gulf_forecast]).reset_index(drop=True)\n",
        "\n",
        "# Show the forecast table\n",
        "from IPython.display import display; display (combined_forecast)\n",
        "\n",
        "# Save file as csv\n",
        "combined_forecast.to_csv(\"vibrio_sarima_60mo_forecast.csv\", index=False)\n",
        "\n",
        "# Download file\n",
        "from google.colab import files\n",
        "# files.download(\"vibrio_sarima_60mo_forecast.csv\")"
      ],
      "metadata": {
        "id": "KoF-POXFrYmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Historical Data with forecast data East Coast\n",
        "# Step 1: Obtain data\n",
        "github = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df = pd.read_csv(github)\n",
        "\n",
        "# Step 2: Filter and aggregate data for East region\n",
        "df_east = df[df['region'] == 'East']\n",
        "df_east['Date'] = pd.to_datetime(df_east[['Year', 'Month']].assign(DAY=1))\n",
        "east_monthly = df_east.groupby('Date')['Number_of_isolates'].sum().reset_index()\n",
        "east_series = east_monthly.set_index('Date')['Number_of_isolates'].asfreq('MS').fillna(0)\n",
        "\n",
        "# Step 3: Fit SARIMA model to entire East Coast data\n",
        "sarima_model = SARIMAX(\n",
        "    east_series,\n",
        "    order=(1, 1, 1),\n",
        "    seasonal_order=(1, 1, 1, 12),\n",
        "    enforce_stationarity=False,\n",
        "    enforce_invertibility=False\n",
        ").fit(disp=False)\n",
        "\n",
        "# Step 4: Forecast 60 months into the future\n",
        "forecast_steps = 60\n",
        "forecast_result = sarima_model.get_forecast(steps=forecast_steps)\n",
        "forecast_mean = forecast_result.predicted_mean.clip(lower=0)\n",
        "forecast_ci = forecast_result.conf_int().clip(lower=0)\n",
        "\n",
        "# Step 5: Create future date range and organize forecast DataFrame\n",
        "last_date = east_series.index.max()\n",
        "future_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), periods=forecast_steps, freq='MS')\n",
        "\n",
        "forecast_df = pd.DataFrame({\n",
        "    'Date': future_dates,\n",
        "    'Region': 'East',\n",
        "    'Forecast': forecast_mean.values,\n",
        "    'Lower_CI': forecast_ci.iloc[:, 0].astype(float).values,\n",
        "    'Upper_CI': forecast_ci.iloc[:, 1].astype(float).values\n",
        "})\n",
        "\n",
        "# Step 6: Merge historical and forecast data\n",
        "historical_df = east_series.reset_index().rename(columns={'Number_of_isolates': 'Observed'})\n",
        "historical_df['Region'] = 'East'\n",
        "\n",
        "merged_df = pd.merge(historical_df, forecast_df, on=['Date', 'Region'], how='outer')\n",
        "merged_df['Forecast'] = pd.to_numeric(merged_df['Forecast'], errors='coerce')\n",
        "merged_df['Lower_CI'] = pd.to_numeric(merged_df['Lower_CI'], errors='coerce')\n",
        "merged_df['Upper_CI'] = pd.to_numeric(merged_df['Upper_CI'], errors='coerce')\n",
        "merged_df['Observed'] = pd.to_numeric(merged_df['Observed'], errors='coerce')\n",
        "merged_df['Date'] = pd.to_datetime(merged_df['Date'], errors='coerce')\n",
        "\n",
        "# Step 7: Drop rows with NaNs in confidence intervals (for plotting)\n",
        "plot_df = merged_df.dropna(subset=['Lower_CI', 'Upper_CI', 'Forecast', 'Date'])\n",
        "\n",
        "# Step 8: Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(merged_df['Date'], merged_df['Observed'], label='Observed', color='black', marker='o')\n",
        "plt.plot(merged_df['Date'], merged_df['Forecast'], label='Forecast', linestyle='--', color='blue')\n",
        "plt.fill_between(\n",
        "    plot_df['Date'].values,\n",
        "    plot_df['Lower_CI'].astype('float64').values,\n",
        "    plot_df['Upper_CI'].astype('float64').values,\n",
        "    color='blue', alpha=0.2, label='95% CI'\n",
        ")\n",
        "\n",
        "plt.title(\"East Coast - Observed and Forecasted Vibrio vulnificus Isolates (SARIMA)\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Isolates\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-4OL1Iv-rdsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "github = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df = pd.read_csv(github)\n",
        "df['Date'] = pd.to_datetime(df[['Year', 'Month']].assign(day=1))\n",
        "\n",
        "# Step 2: Filter and aggregate data for Gulf region\n",
        "df_gulf = df[df['region'] == 'Gulf']\n",
        "gulf_monthly = df_gulf.groupby('Date')['Number_of_isolates'].sum().reset_index()\n",
        "gulf_series = gulf_monthly.set_index('Date')['Number_of_isolates'].asfreq('MS').fillna(0)\n",
        "\n",
        "# Step 3: Fit SARIMA model to entire Gulf Coast data\n",
        "sarima_model = SARIMAX(\n",
        "    gulf_series,\n",
        "    order=(1, 1, 1),\n",
        "    seasonal_order=(1, 1, 1, 12),\n",
        "    enforce_stationarity=False,\n",
        "    enforce_invertibility=False\n",
        ").fit(disp=False)\n",
        "\n",
        "# Step 4: Forecast 60 months into the future\n",
        "forecast_steps = 60\n",
        "forecast_result = sarima_model.get_forecast(steps=forecast_steps)\n",
        "forecast_mean = forecast_result.predicted_mean.clip(lower=0)\n",
        "forecast_ci = forecast_result.conf_int().clip(lower=0)\n",
        "\n",
        "# Step 5: Create future date range and organize forecast DataFrame\n",
        "last_date = gulf_series.index.max()\n",
        "future_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), periods=forecast_steps, freq='MS')\n",
        "\n",
        "forecast_df = pd.DataFrame({\n",
        "    'Date': future_dates,\n",
        "    'Region': 'Gulf',\n",
        "    'Forecast': forecast_mean.values,\n",
        "    'Lower_CI': forecast_ci.iloc[:, 0].astype(float).values,\n",
        "    'Upper_CI': forecast_ci.iloc[:, 1].astype(float).values\n",
        "})\n",
        "\n",
        "# Step 6: Merge historical and forecast data\n",
        "historical_df = gulf_series.reset_index().rename(columns={'Number_of_isolates': 'Observed'})\n",
        "historical_df['Region'] = 'Gulf'\n",
        "\n",
        "merged_df = pd.merge(historical_df, forecast_df, on=['Date', 'Region'], how='outer')\n",
        "merged_df['Forecast'] = pd.to_numeric(merged_df['Forecast'], errors='coerce')\n",
        "merged_df['Lower_CI'] = pd.to_numeric(merged_df['Lower_CI'], errors='coerce')\n",
        "merged_df['Upper_CI'] = pd.to_numeric(merged_df['Upper_CI'], errors='coerce')\n",
        "merged_df['Observed'] = pd.to_numeric(merged_df['Observed'], errors='coerce')\n",
        "merged_df['Date'] = pd.to_datetime(merged_df['Date'], errors='coerce')\n",
        "\n",
        "# Step 7: Drop rows with NaNs in confidence intervals (for plotting)\n",
        "plot_df = merged_df.dropna(subset=['Lower_CI', 'Upper_CI', 'Forecast', 'Date'])\n",
        "\n",
        "# Step 8: Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(merged_df['Date'], merged_df['Observed'], label='Observed', color='black', marker='o')\n",
        "plt.plot(merged_df['Date'], merged_df['Forecast'], label='Forecast', linestyle='--', color='green')\n",
        "#plt.fill_between(\n",
        "    #plot_df['Date'].values,\n",
        "    #plot_df['Lower_CI'].astype('float64').values,\n",
        "    #plot_df['Upper_CI'].astype('float64').values,\n",
        "    #color='green', alpha=0.2, label='95% CI')\n",
        "\n",
        "plt.title(\"Gulf Coast - Observed and Forecasted Vibrio vulnificus Isolates (SARIMA)\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Isolates\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dbvzcLAvsGFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sea Surface Temperature"
      ],
      "metadata": {
        "id": "Gt6tP5PnsLLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the SSS data from the provided GitHub link\n",
        "url = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df_sss = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows to inspect the data\n",
        "df_sss.head()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert Month and Year into a datetime column\n",
        "df_sss['Date'] = pd.to_datetime(df_sss[['Year', 'Month']].assign(DAY=1))\n",
        "\n",
        "# Group by date and state, then calculate the mean SSS\n",
        "sss_time_series = (\n",
        "    df_sss.groupby(['Date'])['sst']\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.lineplot(data=sss_time_series, x='Date', y='sst', color = \"blue\")\n",
        "plt.title('Sea Surface Temperature (SST) (Â°C)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Mean SST (Â°C)')\n",
        "plt.tight_layout()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tOICt_EisG1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Data\n",
        "url = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df_region = pd.read_csv(url)\n",
        "\n",
        "# Create date column\n",
        "df_region[\"date\"] = pd.to_datetime(df_region[[\"Year\", \"Month\"]].assign(DAY=1))\n",
        "\n",
        "# Group by date and region and calculate average SST\n",
        "regional_sst_avg = df_region.groupby([\"date\", \"region\"])[\"sst\"].mean().reset_index()\n",
        "\n",
        "# Pivot for plotting\n",
        "sst_region_pivot = regional_sst_avg.pivot(index=\"date\", columns=\"region\", values=\"sst\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 7))\n",
        "for region in sst_region_pivot.columns:\n",
        "    plt.plot(sst_region_pivot.index, sst_region_pivot[region], label=region)\n",
        "\n",
        "plt.title(\"Average Monthly Sea Surface Temperature (SST) (Â°C) by Region\", fontsize=14)\n",
        "plt.xlabel(\"Date\", fontsize=12)\n",
        "plt.ylabel(\"SST (Â°C)\", fontsize=12)\n",
        "plt.legend(title=\"Region\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "InVH8UNhsUOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "from prophet import Prophet\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reload the uploaded file\n",
        "url = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Aggregate to national average SST by date\n",
        "df_national = df.groupby(['Year', 'Month']).agg({'sst': 'mean'}).reset_index()\n",
        "df_national['date'] = pd.to_datetime(df_national[['Year', 'Month']].assign(day=1))\n",
        "df_national.set_index('date', inplace=True)\n",
        "sst_series = df_national['sst']\n",
        "\n",
        "# Split into train/test\n",
        "train_size = int(len(sst_series) * 0.85)\n",
        "train, test = sst_series[:train_size], sst_series[train_size:]\n",
        "\n",
        "# SARIMA\n",
        "sarima_model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)).fit(disp=False)\n",
        "sarima_forecast = sarima_model.forecast(steps=len(test))\n",
        "\n",
        "# ARIMA\n",
        "arima_model = ARIMA(train, order=(1, 1, 1)).fit()\n",
        "arima_forecast = arima_model.forecast(steps=len(test))\n",
        "\n",
        "# Prophet\n",
        "df_prophet = df_national[['sst']].reset_index().rename(columns={'date': 'ds', 'sst': 'y'})\n",
        "prophet = Prophet()\n",
        "prophet.fit(df_prophet[:train_size])\n",
        "future = prophet.make_future_dataframe(periods=len(test), freq='MS')\n",
        "forecast_prophet = prophet.predict(future)\n",
        "prophet_forecast = forecast_prophet.iloc[-len(test):]['yhat'].values\n",
        "\n",
        "# Random Forest\n",
        "df_national['sst_lag1'] = df_national['sst'].shift(1)\n",
        "df_national['sst_lag12'] = df_national['sst'].shift(12)\n",
        "df_rf = df_national.dropna()\n",
        "\n",
        "X = df_rf[['sst_lag1', 'sst_lag12']]\n",
        "y = df_rf['sst']\n",
        "X_train, X_test = X.iloc[:train_size-12], X.iloc[train_size-12:]\n",
        "y_train, y_test = y.iloc[:train_size-12], y.iloc[train_size-12:]\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_forecast = rf_model.predict(X_test)\n",
        "\n",
        "# Align all outputs for fair comparison\n",
        "min_len = min(len(test), len(y_test), len(prophet_forecast))\n",
        "test = test[:min_len]\n",
        "arima_forecast = arima_forecast[:min_len]\n",
        "sarima_forecast = sarima_forecast[:min_len]\n",
        "prophet_forecast = prophet_forecast[:min_len]\n",
        "rf_forecast = rf_forecast[:min_len]\n",
        "y_test = y_test[:min_len]\n",
        "\n",
        "# Compare Model Metrics\n",
        "results = {\n",
        "    'Model': ['SARIMA', 'ARIMA', 'Prophet', 'Random Forest'],\n",
        "    'MAE': [\n",
        "        mean_absolute_error(test, sarima_forecast),\n",
        "        mean_absolute_error(test, arima_forecast),\n",
        "        mean_absolute_error(test, prophet_forecast),\n",
        "        mean_absolute_error(y_test, rf_forecast)\n",
        "    ],\n",
        "    'RMSE': [\n",
        "        sqrt(mean_squared_error(test, sarima_forecast)),\n",
        "        sqrt(mean_squared_error(test, arima_forecast)),\n",
        "        sqrt(mean_squared_error(test, prophet_forecast)),\n",
        "        sqrt(mean_squared_error(y_test, rf_forecast))\n",
        "    ]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\",results_df)\n",
        "\n",
        "#Export Validation as a CSV file\n",
        "results_df.to_csv(\"sst_model_validation_scores_comparasion.csv\", index=False)\n",
        "from google.colab import files\n",
        "#files.download(\"sst_model_validation_scores_comparasion.csv\")"
      ],
      "metadata": {
        "id": "1edy7YUtsXBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecast Comparison Plot\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(test.index[:min_len], test[:min_len], label='Actual', color='black')\n",
        "plt.plot(test.index[:min_len], sarima_forecast, label='SARIMA Forecast')\n",
        "plt.plot(test.index[:min_len], arima_forecast, label='ARIMA Forecast')\n",
        "plt.plot(test.index[:min_len], prophet_forecast, label='Prophet Forecast')\n",
        "plt.plot(test.index[:min_len], rf_forecast, label='Random Forest Forecast')\n",
        "plt.legend()\n",
        "plt.title(\"Sea Surface Temperature (Â°C) Forecast Comparison\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Sea Surface Temperature (Â°C)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "24pIsuoGsZQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and prep the dataset\n",
        "url = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Group by year + month to get national average SST\n",
        "df_national = df.groupby(['Year', 'Month']).agg({'sst': 'mean'}).reset_index()\n",
        "df_national['date'] = pd.to_datetime(df_national[['Year', 'Month']].assign(day=1))\n",
        "df_prophet = df_national[['date', 'sst']].rename(columns={'date': 'ds', 'sst': 'y'})\n",
        "\n",
        "df_prophet\n",
        "# Build Prophet model with better constraints\n",
        "model = Prophet(\n",
        "    yearly_seasonality=False,\n",
        "    weekly_seasonality=False,\n",
        "    daily_seasonality=False,\n",
        "    seasonality_mode='additive',\n",
        "    changepoint_prior_scale=0.05  # smaller = smoother trend\n",
        ")\n",
        "\n",
        "# Add custom monthly seasonality (e.g., SST changes through the year)\n",
        "#model.add_seasonality(name='monthly', period=30.5, fourier_order=3)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(df_prophet)\n",
        "\n",
        "# Create 60-month forecast\n",
        "future = model.make_future_dataframe(periods=60, freq='MS')\n",
        "forecast = model.predict(future)\n",
        "\n",
        "# Plot forecast\n",
        "fig1 = model.plot(forecast)\n",
        "plt.title('60-Month SST Forecast (Prophet)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Sea Surface Temperature (Â°C)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot trend and seasonal components\n",
        "fig2 = model.plot_components(forecast)\n",
        "plt.show()\n",
        "\n",
        "# Save and Export Forecast\n",
        "\n",
        "# Rename columns\n",
        "forecast_renamed = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].rename(\n",
        "    columns={\n",
        "        'ds': 'date',\n",
        "        'yhat': 'sst',\n",
        "        'yhat_lower': 'Lower 95% CI',\n",
        "        'yhat_upper': 'Upper 95% CI'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Preview the DataFrame\n",
        "forecast_renamed.isna().sum()\n",
        "\n",
        "# Export to CSV\n",
        "forecast_renamed.to_csv(\"prophet_sst_forecast.csv\", index=False)\n",
        "\n",
        "#from google.colab import files\n",
        "files.download(\"prophet_sst_forecast.csv\")"
      ],
      "metadata": {
        "id": "Xm1yaOPLseKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Histroic and Forecasted data\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Load Data ===\n",
        "# Historical SST data\n",
        "historical_path = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "historical_df = pd.read_csv(historical_path)\n",
        "historical_df['date'] = pd.to_datetime(historical_df[['Year', 'Month']].assign(day=1))\n",
        "historical_sst = historical_df.groupby('date')['sst'].mean().reset_index()\n",
        "\n",
        "# Forecasted SST data (already renamed as: date, sst, Lower 95% CI, Upper 95% CI)\n",
        "forecast_path = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/prophet_sst_forecast.csv\"\n",
        "forecast_df = pd.read_csv(forecast_path)\n",
        "forecast_df['date'] = pd.to_datetime(forecast_df['date'])\n",
        "\n",
        "\n",
        "# === Preprocessing ===\n",
        "# Ensure numeric CI columns\n",
        "forecast_df['Lower 95% CI'] = pd.to_numeric(forecast_df['Lower 95% CI'], errors='coerce')\n",
        "forecast_df['Upper 95% CI'] = pd.to_numeric(forecast_df['Upper 95% CI'], errors='coerce')\n",
        "forecast_df['sst'] = pd.to_numeric(forecast_df['sst'], errors='coerce')\n",
        "forecast_df.dropna(subset=['sst', 'Lower 95% CI', 'Upper 95% CI'], inplace=True)\n",
        "\n",
        "# Only show forecasted SST *after* the last historical date\n",
        "last_hist_date = historical_sst['date'].max()\n",
        "forecast_only = forecast_df[forecast_df['date'] > last_hist_date]\n",
        "forecast_only\n",
        "\n",
        "# === Plot ===\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Historical SST\n",
        "plt.plot(historical_sst['date'], historical_sst['sst'], label='Historical SST', color='black', marker='o')\n",
        "\n",
        "# Forecasted SST (only after last observed date)\n",
        "plt.plot(forecast_only['date'], forecast_only['sst'], label='Forecasted SST', color='blue')\n",
        "\n",
        "# 95% Confidence Interval for forecast only\n",
        "plt.fill_between(forecast_only['date'].values,\n",
        "                 forecast_only['Lower 95% CI'].values,\n",
        "                 forecast_only['Upper 95% CI'].values,\n",
        "                 color='skyblue', alpha=0.4, label='95% Confidence Interval')\n",
        "\n",
        "\n",
        "# Vertical line at transition\n",
        "plt.axvline(x=forecast_only['date'].min(), color='magenta', linestyle='--', label='Forecast Start', lw = 3, alpha = 0.8)\n",
        "\n",
        "# Labels and formatting\n",
        "plt.title(\"Historical and Forecasted Sea Surface Temperature (SST)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"SST (Â°C)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IIJuUmHqsgQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === Load historical SST ===\n",
        "historical_path = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "historical_df = pd.read_csv(historical_path)\n",
        "historical_df['date'] = pd.to_datetime(historical_df[['Year', 'Month']].assign(day=1))\n",
        "historical_sst = historical_df.groupby('date')['sst'].mean().reset_index()\n",
        "\n",
        "# Rename columns to match forecast format\n",
        "historical_sst_renamed = historical_sst.rename(columns={'sst': 'SST'})\n",
        "historical_sst_renamed['type'] = 'historical'\n",
        "historical_sst_renamed['Lower 95% CI'] = None\n",
        "historical_sst_renamed['Upper 95% CI'] = None\n",
        "\n",
        "# === Load forecasted SST ===\n",
        "forecast_path = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/prophet_sst_forecast.csv\"\n",
        "forecast_df = pd.read_csv(forecast_path)\n",
        "forecast_df['date'] = pd.to_datetime(forecast_df['date'])\n",
        "\n",
        "# Ensure numeric conversion in case of format issues\n",
        "forecast_df['Lower 95% CI'] = pd.to_numeric(forecast_df['Lower 95% CI'], errors='coerce')\n",
        "forecast_df['Upper 95% CI'] = pd.to_numeric(forecast_df['Upper 95% CI'], errors='coerce')\n",
        "forecast_df['sst'] = pd.to_numeric(forecast_df['sst'], errors='coerce')\n",
        "\n",
        "# Format forecasted data\n",
        "forecast_only = forecast_df[['date', 'sst', 'Lower 95% CI', 'Upper 95% CI']].rename(columns={'sst': 'SST'})\n",
        "forecast_only['type'] = 'forecast'\n",
        "\n",
        "# === Combine historical and forecast ===\n",
        "combined_df = pd.concat([historical_sst_renamed, forecast_only], ignore_index=True)\n",
        "\n",
        "# === Export to CSV ===\n",
        "combined_df.to_csv(\"combined_sst_historical_forecast.csv\", index=False)\n",
        "\n",
        "# === Download File ===\n",
        "# import io\n",
        "# from google.colab import files\n",
        "# files.download(\"combined_sst_historical_forecast.csv\")\n"
      ],
      "metadata": {
        "id": "5q8JutgssieY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sea Surface Salinity"
      ],
      "metadata": {
        "id": "uf5aAWQxsn3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Create a 'Date' column for time series visualization\n",
        "df['Date'] = pd.to_datetime(df[['Year', 'Month']].assign(DAY=1))\n",
        "\n",
        "# Group data by date and compute average salinity (sss)\n",
        "sss_time_series = df.groupby('Date')['sss'].mean().reset_index()\n",
        "\n",
        "# Plotting the time series\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(sss_time_series['Date'], sss_time_series['sss'], label='Average SSS (ppt)', linewidth=2)\n",
        "plt.title('Average Sea Surface Salinity (SSS) Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Sea Surface Salinity (SSS)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "jukKVus7sknk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Regions\n",
        "\n",
        "# Load the region-based dataset\n",
        "url = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df_region = pd.read_csv(url)\n",
        "\n",
        "# Create a 'Date' column for time series visualization\n",
        "df_region['Date'] = pd.to_datetime(df_region[['Year', 'Month']].assign(DAY=1))\n",
        "\n",
        "# Group by region and date, then calculate average salinity\n",
        "sss_by_region = df_region.groupby(['region', 'Date'])['sss'].mean().reset_index()\n",
        "\n",
        "# Plotting\n",
        "\n",
        "custom_colors = {\n",
        "    'East': 'purple',\n",
        "    'Gulf': 'forestgreen'\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "for region in sss_by_region['region'].unique():\n",
        "    region_data = sss_by_region[sss_by_region['region'] == region]\n",
        "    plt.plot(region_data['Date'], region_data['sss'], label=region, color = custom_colors.get(region))\n",
        "\n",
        "plt.title('Average Sea Surface Salinity (ppt)Over Time by Region')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Sea Surface Salinity (ppt)')\n",
        "plt.legend(title='Region')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kPO_0qqntJ92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Validation\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from math import sqrt\n",
        "from prophet import Prophet\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df_region = pd.read_csv(url)\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month']].assign(DAY=1))\n",
        "sss_time_series = df.groupby('date')['sss'].mean().reset_index()\n",
        "\n",
        "# Time series setup\n",
        "sss_series = sss_time_series.set_index('date')['sss']\n",
        "train_size = int(len(sss_series) * 0.8)\n",
        "train, test = sss_series[:train_size], sss_series[train_size:]\n",
        "forecast_steps = len(test)\n",
        "\n",
        "# ARIMA\n",
        "arima_model = ARIMA(train, order=(1,1,1))\n",
        "arima_result = arima_model.fit()\n",
        "arima_forecast = arima_result.forecast(steps=forecast_steps)\n",
        "\n",
        "# SARIMA\n",
        "sarima_model = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
        "sarima_result = sarima_model.fit()\n",
        "sarima_forecast = sarima_result.forecast(steps=forecast_steps)\n",
        "\n",
        "# Prophet\n",
        "prophet_df = sss_time_series.rename(columns={'date': 'ds', 'sss': 'y'})\n",
        "prophet_train = prophet_df.iloc[:train_size]\n",
        "prophet_model = Prophet()\n",
        "prophet_model.fit(prophet_train)\n",
        "prophet_future = prophet_df.iloc[train_size:][['ds']]\n",
        "prophet_forecast = prophet_model.predict(prophet_future)['yhat'].values\n",
        "\n",
        "# Random Forest\n",
        "def create_lag_features(series, lags=12):\n",
        "    df_lag = pd.DataFrame({'y': series})\n",
        "    for lag in range(1, lags + 1):\n",
        "        df_lag[f'lag_{lag}'] = series.shift(lag)\n",
        "    df_lag.dropna(inplace=True)\n",
        "    return df_lag\n",
        "\n",
        "rf_data = create_lag_features(sss_series)\n",
        "X = rf_data.drop(columns='y')\n",
        "y = rf_data['y']\n",
        "X_train, X_test = X.iloc[:train_size - 12], X.iloc[train_size - 12:]\n",
        "y_train, y_test = y.iloc[:train_size - 12], y.iloc[train_size - 12:]\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_forecast = rf_model.predict(X_test)\n",
        "\n",
        "# Compare Model Metrics\n",
        "results = {\n",
        "    'Model': ['SARIMA', 'ARIMA', 'Prophet', 'Random Forest'], # Add 'Prophet' if you enable it\n",
        "    'MAE': [\n",
        "        mean_absolute_error(test, sarima_forecast),\n",
        "        mean_absolute_error(test, arima_forecast),\n",
        "        mean_absolute_error(test, prophet_forecast),\n",
        "        mean_absolute_error(y_test, rf_forecast)\n",
        "    ],\n",
        "    'RMSE': [\n",
        "        sqrt(mean_squared_error(test, sarima_forecast)),\n",
        "        sqrt(mean_squared_error(test, arima_forecast)),\n",
        "        sqrt(mean_squared_error(test, prophet_forecast)),\n",
        "        sqrt(mean_squared_error(y_test, rf_forecast))\n",
        "    ]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print('\\n', results_df)\n",
        "\n",
        "results_df.to_csv(\"sss_model_validation_scores_comparasion.csv\", index=False)\n",
        "from google.colab import files\n",
        "files.download(\"sss_model_validation_scores_comparasion.csv\")\n"
      ],
      "metadata": {
        "id": "hsW9UgL2tOjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Build full results_df for plotting\n",
        "results_df = pd.DataFrame({\n",
        "    'date': test.index,\n",
        "    'actual': test.values,\n",
        "    'ARIMA': arima_forecast.values,\n",
        "    'SARIMA': sarima_forecast.values,\n",
        "    'Prophet': prophet_forecast,\n",
        "    'Random Forest': rf_forecast\n",
        "})\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(results_df['date'], results_df['actual'], label='Actual', color='black', linewidth=2)\n",
        "plt.plot(results_df['date'], results_df['ARIMA'], label='ARIMA', linestyle='--')\n",
        "plt.plot(results_df['date'], results_df['SARIMA'], label='SARIMA', linestyle='--')\n",
        "plt.plot(results_df['date'], results_df['Prophet'], label='Prophet', linestyle='--')  # Uncomment locally\n",
        "plt.plot(results_df['date'], results_df['Random Forest'], label='Random Forest', linestyle='--')\n",
        "\n",
        "plt.title('Model Forecasts vs Actual Sea Surface Salinity (SSS)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('SSS (ppt)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0Hz21BBHtTwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Rebuild full dataset with lag features and seasonal indicators\n",
        "sss_series = sss_time_series.set_index('date')['sss']\n",
        "data = pd.DataFrame({'y': sss_series})\n",
        "for lag in range(1, 13):\n",
        "    data[f'lag_{lag}'] = data['y'].shift(lag)\n",
        "data['month'] = data.index.month\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Split into features and target\n",
        "X = data.drop(columns='y')\n",
        "y = data['y']\n",
        "\n",
        "# Train on full data\n",
        "rf_model = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
        "rf_model.fit(X, y)\n",
        "\n",
        "# Forecast the next 60 months\n",
        "last_known = data.copy()\n",
        "forecast_months = 60\n",
        "predictions = []\n",
        "\n",
        "for i in range(forecast_months):\n",
        "    last_row = last_known.iloc[-1]\n",
        "    new_month = (last_row.name.month % 12) + 1\n",
        "    lags = last_known['y'].iloc[-12:].values[::-1]  # last 12 months in reverse order\n",
        "    new_input = dict(zip([f'lag_{j+1}' for j in range(12)], lags))\n",
        "    new_input['month'] = new_month\n",
        "    new_input_df = pd.DataFrame([new_input])\n",
        "    pred = rf_model.predict(new_input_df)[0]\n",
        "    predictions.append(pred)\n",
        "\n",
        "    # Append the new forecast to the end of last_known\n",
        "    next_date = last_known.index[-1] + pd.DateOffset(months=1)\n",
        "    row = pd.Series({'y': pred, **new_input}, name=next_date)\n",
        "    last_known = pd.concat([last_known, pd.DataFrame([row])])\n",
        "\n",
        "# Build forecast DataFrame\n",
        "forecast_dates = pd.date_range(start=last_known.index[-forecast_months], periods=forecast_months, freq='MS')\n",
        "forecast_df = pd.DataFrame({'date': forecast_dates, 'sss_forecast': predictions})\n",
        "\n",
        "# Combine historical and forecast for plotting\n",
        "combined_df = pd.concat([\n",
        "    sss_time_series.rename(columns={'sss': 'sss_forecast'})[['date', 'sss_forecast']],\n",
        "    forecast_df\n",
        "])\n",
        "\n",
        "# Split historical and forecasted data for separate color plotting\n",
        "historical_df = combined_df[combined_df['date'] <= sss_time_series['date'].max()]\n",
        "future_df = combined_df[combined_df['date'] > sss_time_series['date'].max()]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(historical_df['date'], historical_df['sss_forecast'], label='Historical SSS', color='blue', linewidth=2)\n",
        "plt.plot(future_df['date'], future_df['sss_forecast'], label='Forecasted SSS (Random Forest)', color='purple', linestyle='--', linewidth=2)\n",
        "plt.axvline(x=sss_time_series['date'].max(), color='red', linestyle='--', label='Forecast Start')\n",
        "plt.title('Random Forest Forecast (60 Months) with Historical SSS Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Sea Surface Salinity (ppt)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "from IPython.display import display\n",
        "display(combined_df)\n"
      ],
      "metadata": {
        "id": "WIVgMbgptXJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export Data\n",
        "# combined_df.to_csv(\"random_forest_sss_forecast.csv\", index=False)\n",
        "\n",
        "# Download it\n",
        "# from google.colab import files\n",
        "# files.download(\"random_forest_sss_forecast.csv\")"
      ],
      "metadata": {
        "id": "bdm0FTeYtZeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "60 Month Forecasting"
      ],
      "metadata": {
        "id": "L_7AyugxugRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the data\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the historical data\n",
        "url = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg_region.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "\n",
        "\n",
        "# Create a datetime column for temporal visualizations\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month']].assign(day=1))\n",
        "\n",
        "# Set up the visual style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Scatter: SST vs Isolates\n",
        "sns.scatterplot(data=df, x='sst', y='Number_of_isolates', hue='state_name', ax=axs[0, 0])\n",
        "axs[0, 0].set_title('SST vs Number of Isolates')\n",
        "axs[0, 0].set_xlabel('Sea Surface Temperature (Â°C)')\n",
        "axs[0, 0].set_ylabel('Number of Vibrio Isolates')\n",
        "axs[0, 0].legend(title='State')\n",
        "\n",
        "# Scatter: SSS vs Isolates\n",
        "sns.scatterplot(data=df, x='sss', y='Number_of_isolates', hue='state_name', ax=axs[0, 1])\n",
        "axs[0, 1].set_title('SSS vs Number of Isolates')\n",
        "axs[0, 1].set_xlabel('Sea Surface Salinity (ppt)')\n",
        "axs[0, 1].set_ylabel('Number of Vibrio Isolates')\n",
        "axs[0, 1].legend(title='State')\n",
        "\n",
        "# Correlation Heatmap\n",
        "corr = df[['sst', 'sss', 'Number_of_isolates']].corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', ax=axs[1, 0],\n",
        "             xticklabels=['Sea Surface Temp (Â°C)', 'Sea Surface Salinity (ppt)', 'Vibrio Isolates'],\n",
        "            yticklabels=['Sea Surface Temp (Â°C)', 'Sea Surface Salinity (ppt)', 'Vibrio Isolates'])\n",
        "axs[1, 0].set_title('Correlation Matrix')\n",
        "axs[1, 0].tick_params(axis='x', labelrotation=30)\n",
        "axs[1, 0].tick_params(axis='y', labelrotation=0)\n",
        "\n",
        "# Line plot\n",
        "sns.lineplot(data=df, x='date', y='Number_of_isolates', hue='region', marker='o', ax=axs[1, 1], ci = None)\n",
        "axs[1, 1].set_title('Number of Isolates Over Time')\n",
        "axs[1, 1].set_xlabel('Date')\n",
        "axs[1, 1].set_ylabel('Number of Vibrio Isolates')\n",
        "axs[1, 1].legend(title='Region')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hvzflVRAtciW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import numpy as np\n",
        "\n",
        "# Load the historical data\n",
        "url = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Create a datetime column for temporal visualizations\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month']].assign(day=1))\n",
        "\n",
        "# Prepare dataset\n",
        "df_sorted = df.sort_values(\"date\").copy()\n",
        "df_sorted['sst_lag1'] = df_sorted['sst'].shift(1)\n",
        "df_sorted['sss_lag1'] = df_sorted['sss'].shift(1)\n",
        "df_model = df_sorted.dropna(subset=['sst_lag1', 'sss_lag1'])\n",
        "\n",
        "# Features and target\n",
        "X = df_model[['sst', 'sss', 'sst_lag1', 'sss_lag1']]\n",
        "y = df_model['Number_of_isolates']\n",
        "\n",
        "# TimeSeries cross-validation\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "results = {\n",
        "    'Model': [],\n",
        "    'MAE': [],\n",
        "    'RMSE': []\n",
        "}\n",
        "\n",
        "# SARIMAX (fitted once, not cross-validated due to stateful nature)\n",
        "sarimax_model = SARIMAX(\n",
        "    y, exog=X, order=(1, 0, 1), seasonal_order=(1, 0, 1, 12), enforce_stationarity=False, enforce_invertibility=False\n",
        ").fit(disp=False)\n",
        "sarimax_pred = sarimax_model.predict(start=0, end=len(y)-1, exog=X)\n",
        "results['Model'].append('SARIMAX')\n",
        "results['MAE'].append(mean_absolute_error(y, sarimax_pred))\n",
        "results['RMSE'].append(np.sqrt(mean_squared_error(y, sarimax_pred)))\n",
        "\n",
        "# Random Forest & XGBoost with CV\n",
        "for model_name, model in {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBRegressor(n_estimators=100, learning_rate=0.1, objective='reg:squarederror', random_state=42)\n",
        "}.items():\n",
        "    maes, rmses = [], []\n",
        "    for train_idx, test_idx in tscv.split(X):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        maes.append(mean_absolute_error(y_test, y_pred))\n",
        "        rmses.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "    results['Model'].append(model_name)\n",
        "    results['MAE'].append(np.mean(maes))\n",
        "    results['RMSE'].append(np.mean(rmses))\n",
        "\n",
        "# Present the results in a table\n",
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "from IPython.display import display\n",
        "\n",
        "display(results_df)\n",
        "\n",
        "results_df.to_csv(\"sst_sss_model_validation_results.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "# files.download(\"sst_sss_model_validation_results.csv\")\n"
      ],
      "metadata": {
        "id": "splzereoteqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VIsualize the Data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Refit Random Forest and XGBoost on the full dataset\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X, y)\n",
        "rf_pred = rf_model.predict(X)\n",
        "\n",
        "xgb_model = XGBRegressor(n_estimators=2000, learning_rate=0.001, objective='reg:squarederror', random_state=42)\n",
        "xgb_model.fit(X, y)\n",
        "xgb_pred = xgb_model.predict(X)\n",
        "\n",
        "# SARIMAX prediction already done earlier as sarimax_pred\n",
        "\n",
        "# Plot all models vs actual\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(df_model['date'], y, label='Actual', marker='o', linewidth=2)\n",
        "plt.plot(df_model['date'], sarimax_pred, label='SARIMAX', linestyle='--')\n",
        "plt.plot(df_model['date'], rf_pred, label='Random Forest', linestyle='--')\n",
        "plt.plot(df_model['date'], xgb_pred, label='XGBoost', linestyle='--')\n",
        "\n",
        "plt.title('Actual vs Predicted Number of Vibrio Isolates')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Isolates')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLZS3zqytjau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Prepare the dataset\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month']].assign(day=1))\n",
        "df = df.sort_values(\"date\")\n",
        "df['sst_lag1'] = df['sst'].shift(1)\n",
        "df['sss_lag1'] = df['sss'].shift(1)\n",
        "df_model = df.dropna(subset=['sst_lag1', 'sss_lag1'])\n",
        "\n",
        "# Define features and target\n",
        "X = df_model[['sst', 'sss', 'sst_lag1', 'sss_lag1']]\n",
        "y = df_model['Number_of_isolates']\n",
        "dates = df_model['date']\n",
        "\n",
        "# Split: use last 12 months as test set\n",
        "train_size = -12\n",
        "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
        "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
        "dates_test = dates.iloc[train_size:]\n",
        "\n",
        "# Train and predict with Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Train and predict with XGBoost\n",
        "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, objective='reg:squarederror', random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Train and predict with SARIMAX\n",
        "sarimax_model = SARIMAX(\n",
        "    y_train, exog=X_train, order=(1, 0, 1), seasonal_order=(1, 0, 1, 12),\n",
        "    enforce_stationarity=False, enforce_invertibility=False\n",
        ").fit(disp=False)\n",
        "sarimax_pred = sarimax_model.predict(start=len(y_train), end=len(y_train)+len(y_test)-1, exog=X_test)\n",
        "\n",
        "# Plot actual vs predicted for the holdout period\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(dates_test, y_test, label='Actual', marker='o')\n",
        "plt.plot(dates_test, sarimax_pred, label='SARIMAX', linestyle='--')\n",
        "plt.plot(dates_test, rf_pred, label='Random Forest', linestyle='--')\n",
        "plt.plot(dates_test, xgb_pred, label='XGBoost', linestyle='--')\n",
        "\n",
        "plt.title(\"Forecast Accuracy on Last 12 Months (Holdout Set)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of Isolates\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "00fX3cfStlnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**\n",
        "\n",
        "**SARIMAX:**\tCaptures time/seasonality structure\tCan underperform with complex non-linear relationships and make unrealistic predictions (e.g. < 0)\n",
        "\n",
        "**Random Forest:**\tStable and interpretable\tStruggles with sharp peaks, can smooth too much\n",
        "\n",
        "**XGBoost:**\tHighly flexible, fits peaks well\tRisk of overfitting; less interpretable\n",
        "\n",
        "Holdout data is data not used for training"
      ],
      "metadata": {
        "id": "RzGJ2MS1vvVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 60 Month Forecast\n",
        "\n",
        "# Merge forecasted SSS and SST\n",
        "# Load the corrected forecast files\n",
        "url_sss = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/random_forest_sss_forecast.csv\"\n",
        "url_sst = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/combined_sst_historical_forecast.csv\"\n",
        "sss_df = pd.read_csv(url_sss)\n",
        "sst_df = pd.read_csv(url_sst)\n",
        "print(sss_df.columns, sst_df.columns)\n",
        "\n",
        "# Ensure proper datetime formatting\n",
        "sst_df['date'] = pd.to_datetime(sst_df['date'])\n",
        "sss_df['date'] = pd.to_datetime(sss_df['date'])\n",
        "\n",
        "# Merge both forecasts on date\n",
        "merged_forecast = pd.merge(sst_df[['date', 'SST']], sss_df[['date', 'sss_forecast']], on='date', how='inner')\n",
        "merged_forecast.rename(columns={'SST': 'sst_forecast'}, inplace=True)\n",
        "\n",
        "# Sort and add lag features\n",
        "merged_forecast = merged_forecast.sort_values('date')\n",
        "merged_forecast.reset_index(drop=True, inplace=True)\n",
        "merged_forecast['sst_lag1'] = merged_forecast['sst_forecast'].shift(1)\n",
        "merged_forecast['sss_lag1'] = merged_forecast['sss_forecast'].shift(1)\n",
        "\n",
        "# Drop rows with missing lag values (only the first one)\n",
        "#forecast_ready = merged_forecast.dropna().copy()\n",
        "\n",
        "# Show the structure of the prepared forecast input\n",
        "merged_forecast.head()"
      ],
      "metadata": {
        "id": "A3DY_httuWAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 1: Load and Prepare Projected SST/SSS\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Merge forecasted SSS and SST\n",
        "# Load the corrected forecast files\n",
        "url_sss = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/random_forest_sss_forecast.csv\"\n",
        "url_sst = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/combined_sst_historical_forecast.csv\"\n",
        "sss_df = pd.read_csv(url_sss)\n",
        "sst_df = pd.read_csv(url_sst)\n",
        "print(sss_df.columns, sst_df.columns)\n",
        "\n",
        "# Ensure proper datetime formatting\n",
        "sst_df['date'] = pd.to_datetime(sst_df['date'])\n",
        "sss_df['date'] = pd.to_datetime(sss_df['date'])\n",
        "\n",
        "# Merge both forecasts on date\n",
        "merged_forecast = pd.merge(sst_df[['date', 'SST']], sss_df[['date', 'sss_forecast']], on='date', how='inner')\n",
        "merged_forecast.rename(columns={'SST': 'sst_forecast'}, inplace=True)\n",
        "\n",
        "# Sort and add lag features\n",
        "merged_forecast = merged_forecast.sort_values('date')\n",
        "merged_forecast.reset_index(drop=True, inplace=True)\n",
        "merged_forecast['sst_lag1'] = merged_forecast['sst_forecast'].shift(1)\n",
        "merged_forecast['sss_lag1'] = merged_forecast['sss_forecast'].shift(1)\n",
        "\n",
        "# Drop missing lags\n",
        "forecast_ready = merged_forecast.dropna().copy()\n",
        "\n",
        "\n",
        "# STEP 2: Load and Prepare Historical Data\n",
        "\n",
        "\n",
        "# Load historical Vibrio data with SST/SSS\n",
        "url_hist = \"https://raw.githubusercontent.com/AnkurBambhrolia/Vibrio/refs/heads/main/vv_sst_sss_sources_avg.csv\"\n",
        "df = pd.read_csv(url_hist)\n",
        "\n",
        "# Convert to datetime\n",
        "df['date'] = pd.to_datetime(df[['Year', 'Month']].assign(day=1))\n",
        "df = df.sort_values('date')\n",
        "\n",
        "# Create lag features\n",
        "df['sst_lag1'] = df['sst'].rolling(window=12).mean().shift(1) # Ran 3 times: Lag 1, Rolling 12, and Lag 1 + Rolling 12\n",
        "df['sss_lag1'] = df['sss'].rolling(window=12).mean().shift(1) # Ran 3 times: Lag 1, Rolling 12, and Lag 1 + Rolling 12\n",
        "\n",
        "#rolling(window=12).mean()\n",
        "# Drop NA\n",
        "df_model = df.dropna(subset=['sst_lag1', 'sss_lag1'])\n",
        "\n",
        "# Define training data\n",
        "X_train = df_model[['sst', 'sss', 'sst_lag1', 'sss_lag1']]\n",
        "y_train = df_model['Number_of_isolates']\n",
        "\n",
        "\n",
        "# STEP 3: Train SARIMAX Model\n",
        "\n",
        "\n",
        "sarimax_model = SARIMAX(\n",
        "    y_train, exog=X_train,\n",
        "    order=(1, 0, 1),\n",
        "    seasonal_order=(1, 0, 1, 12),\n",
        "    enforce_stationarity=False,\n",
        "    enforce_invertibility=False\n",
        ").fit(disp=False)\n",
        "\n",
        "# STEP 4: Forecast Future Cases\n",
        "\n",
        "\n",
        "# Forecast only for future dates (after training data ends)\n",
        "last_train_date = df_model['date'].max()\n",
        "future_input = forecast_ready[forecast_ready['date'] > last_train_date].copy()\n",
        "\n",
        "# Prepare future exog variables\n",
        "X_future = future_input[['sst_forecast', 'sss_forecast', 'sst_lag1', 'sss_lag1']]\n",
        "X_future.columns = ['sst', 'sss', 'sst_lag1', 'sss_lag1']\n",
        "\n",
        "# Forecast\n",
        "forecast = sarimax_model.predict(\n",
        "    start=len(y_train),\n",
        "    end=len(y_train) + len(X_future) - 1,\n",
        "    exog=X_future\n",
        ")\n",
        "forecast = np.clip(forecast, 0, None)\n",
        "\n",
        "# Fix index mismatch by assigning forecast by position\n",
        "# Ensure DataFrame is same length as forecast\n",
        "future_input = future_input.iloc[:len(forecast)].copy()\n",
        "future_input['forecasted_isolates'] = forecast.values\n",
        "\n",
        "# STEP 5: Plot the Results\n",
        "\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(df_model['date'], y_train, label='Historical', marker='o')\n",
        "plt.plot(future_input['date'], future_input['forecasted_isolates'], label='Forecast (Next 60 Months)', marker='x', linestyle='--')\n",
        "plt.axvline(last_train_date, color='magenta', linestyle=':', label='Forecast Start')\n",
        "plt.title(\"Vibrio vulnificus Forecast (60-Month Projection)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of Isolates\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# STEP 6: Export Forecast\n",
        "\n",
        "\n",
        "# Save to CSV\n",
        "future_input.columns\n",
        "future_input[['date', 'forecasted_isolates','sss_forecast','sst_forecast','sst_lag1','sss_lag1']].to_csv(\"vv_forecast_60_months_final.csv\", index=False)\n",
        "from google.colab import files\n",
        "#files.download(\"vv_forecast_60_months_final.csv\")"
      ],
      "metadata": {
        "id": "uc-3SZrgv1Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Validation for each modification in lag and rolling window\n",
        "\n",
        "print(\"AIC:\", sarimax_model.aic)\n",
        "print(\"BIC:\", sarimax_model.bic)"
      ],
      "metadata": {
        "id": "YAGqM-JKv4eT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}